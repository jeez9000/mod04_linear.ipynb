{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7257fa6d",
   "metadata": {},
   "source": [
    "# Module 04: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split \n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS, summarize)\n",
    "\n",
    "# set seed\n",
    "seed = 4721"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbffdac",
   "metadata": {},
   "source": [
    "### We'll use the _Bikeshare_ data from ISLP for this activity. The metadata for _Bikeshare_ can be found [here](https://intro-stat-learning.github.io/ISLP/datasets/Bikeshare.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Bikeshare = load_data('Bikeshare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c971e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the columns and their types\n",
    "Bikeshare.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0b523",
   "metadata": {},
   "source": [
    "### We will predict the `bikers` column, which is the total of casual and registered bikers. \n",
    "Then we can create a matrix of potential independent variables (X) and a dependent variable vector (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_vars = ['season', 'mnth', 'day', 'hr', \n",
    "              'holiday', 'weekday', 'workingday', \n",
    "              'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "\n",
    "X = Bikeshare[indep_vars]\n",
    "y = Bikeshare['bikers']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca23bc6",
   "metadata": {},
   "source": [
    "### Before doing any other analyses, let's create training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ec7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, Train, Test = train_test_split(X, y, Bikeshare, \n",
    "                                                                 random_state = seed, \n",
    "                                                                 test_size = 0.25, \n",
    "                                                                 shuffle = True)\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20e360",
   "metadata": {},
   "source": [
    "### We can first summarize the variables in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d87783",
   "metadata": {},
   "source": [
    "### Then we can create plots for each potential independent variable with `bikers` on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plots before drawing them\n",
    "nrows = 4\n",
    "ncols = 3\n",
    "figsize = (5*nrows, 5*ncols)\n",
    "\n",
    "fig, axes = subplots(nrows=nrows,\n",
    "                     ncols=ncols,\n",
    "                     figsize=figsize)\n",
    "\n",
    "# Assign a grid location to each index\n",
    "def range_to_grid(i, nrows, ncols):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for n in range(nrows*ncols):\n",
    "        x.append(n // ncols)\n",
    "        y.append(n % ncols)\n",
    "        # print(n,x[n],y[n]) # for testing this function\n",
    "    return x[i],y[i]\n",
    "\n",
    "# Plot the variables\n",
    "for j in range(len(X_train.columns)):\n",
    "    # print(range_to_grid(j,nrows,ncols)[0], range_to_grid(j,nrows,ncols)[1]) # testing\n",
    "    axes[range_to_grid(j,nrows,ncols)[0],\n",
    "         range_to_grid(j,nrows,ncols)[1]].plot(X_train.iloc[:,j], y_train, 'o')\n",
    "    axes[range_to_grid(j,nrows,ncols)[0],\n",
    "         range_to_grid(j,nrows,ncols)[1]].set_xlabel(X_train.columns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff1b06",
   "metadata": {},
   "source": [
    "### Explain why you can deduce that there likely are no missing values in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e7ca5",
   "metadata": {},
   "source": [
    "#fillin Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe36fc5",
   "metadata": {},
   "source": [
    "This is because Train.describe() shows the same count for all columns, indicating no missing values in the training set. Since the training set is a random sample of the full dataset, it's likely the full dataset also has no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d682b",
   "metadata": {},
   "source": [
    "### The variables that have approximately linear relationship with `bikers` are `temp`, `atemp`, `windspeed`, `workingday`, and `holiday`. \n",
    "\n",
    "It appears that time-related variables (`season`, `day`, `hr`, etc.) have non-linear relationships with `bikers`, so we'll hold off on using these variables until the next module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of potential linear variables\n",
    "Train[['bikers', 'temp', 'atemp', 'windspeed', 'workingday', 'holiday']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d307418",
   "metadata": {},
   "source": [
    "### Explain why `temp` or `atemp` should be used to predict `bikers`, but NOT both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd47d9",
   "metadata": {},
   "source": [
    "#fillin Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa6808",
   "metadata": {},
   "source": [
    " They are highly correlated, which can lead to unstable coefficient estimates and difficulty in interpreting individual effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c2cd2",
   "metadata": {},
   "source": [
    "## First Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b41d7",
   "metadata": {},
   "source": [
    "### We can create a column to represent the intercept in our model. \n",
    "\n",
    "Some packages do this automatically, but we will leverage the ISLP version, which does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec0b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['intercept'] = np.ones(X_train.shape[0])\n",
    "X_test['intercept'] = np.ones(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17ce40",
   "metadata": {},
   "source": [
    "### Now we'll build a simple linear regression model that uses only `temp` and an intercept to predict `bikers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17dea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = sm.OLS(y_train, X_train[['intercept','temp']])\n",
    "results_1 = model_1.fit()\n",
    "summarize(results_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f9713",
   "metadata": {},
   "source": [
    "### Use this model to predict the number of bikers on a 68F day. \n",
    "\n",
    "_Hint_: Use the [metadata](https://intro-stat-learning.github.io/ISLP/datasets/Bikeshare.html) and the fact that 68F = 20C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc6db16",
   "metadata": {},
   "source": [
    "#fillin Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bdc1d",
   "metadata": {},
   "source": [
    "Thius model predicts around 370 bikers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a4875",
   "metadata": {},
   "source": [
    "### We will evaluate this model *three ways*: Using R^2, using MSE, and then visually. \n",
    "\n",
    "For the last two, we will compare on _Train_ and on _Test_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d517dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 on training\n",
    "results_1.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helper functions for computing the mean squared error\n",
    "\n",
    "def predict(X, model):\n",
    "    # the built-in get_prediction tool returns an array, so we need to convert to a dataframe\n",
    "    predictions_df = pd.DataFrame(model.get_prediction(X).predicted, columns=['y_hat'], index=X.index)\n",
    "    return predictions_df['y_hat']\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    # calculate the residual error for each individual record\n",
    "    resid = y - y_hat\n",
    "    # square the residual (hence \"squared error\")\n",
    "    sq_resid = resid**2\n",
    "    # calculate the sum of squared errors\n",
    "    SSR = sum(sq_resid)\n",
    "    # divide by the number of records to get the mean squared error\n",
    "    MSE = SSR / y.shape[0]\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_1 = predict(X_train[['intercept', 'temp']], results_1)\n",
    "print('MSE train: ', mse(y_train, predictions_train_1))\n",
    "\n",
    "predictions_test_1 = predict(X_test[['intercept', 'temp']], results_1)\n",
    "print('MSE test: ', mse(y_test, predictions_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to draw a line given coefficients [credit to Hastie & Tibshirani]\n",
    "\n",
    "def abline(ax, b, m, *args, **kwargs):\n",
    "    \"Add a line with slope m and intercept b to ax\"\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = [m * xlim[0] + b, m * xlim[1] + b]\n",
    "    ax.plot(xlim, ylim, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Train.plot.scatter('temp', 'bikers')\n",
    "ax.set_title(\"Plot of temp vs bikers (train)\")\n",
    "abline(ax,\n",
    "       results_1.params[0],\n",
    "       results_1.params[1],\n",
    "       'r--',\n",
    "       linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Test.plot.scatter('temp', 'bikers')\n",
    "ax.set_title(\"Plot of temp vs bikers (test)\")\n",
    "abline(ax,\n",
    "       results_1.params[0],\n",
    "       results_1.params[1],\n",
    "       'm--',\n",
    "       linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c04cdf",
   "metadata": {},
   "source": [
    "### Using the same training set, build a new model that uses both temp and holiday to predict bikers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = #fillin\n",
    "results_2 = #fillin\n",
    "summarize(results_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f9093",
   "metadata": {},
   "source": [
    "### Based on the summary of the new model, does it make sense to include `holiday` as a predictor? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d113e",
   "metadata": {},
   "source": [
    "#fillin Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca59b9",
   "metadata": {},
   "source": [
    "Yes, it makes sense. The pâ€‘value for the holiday coefficient is very small, indicating that holiday is statistically significant. Moreover, the coefficient is negative, so the variable adds meaningful explanatory power to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865a763",
   "metadata": {},
   "source": [
    "### Compute the R^2 coefficient for the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillin\n",
    "results_2.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf9599d",
   "metadata": {},
   "source": [
    "### Compute the MSE on the training and test sets for the new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab212d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_2 =  predict(X_train[['intercept','temp','holiday']], results_2)\n",
    "\n",
    "predictions_test_2 = predict(X_test[['intercept','temp','holiday']], results_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a2836",
   "metadata": {},
   "source": [
    "### Based on the MSE calculations, is this model better or worse than the model containing only `temp`? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccd439",
   "metadata": {},
   "source": [
    "Model 2  is better than Model 1. The test MSE for Model 2 is lower than the test MSE for Model 1, indicating that Model 2 predicts more accurately on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022b435",
   "metadata": {},
   "source": [
    "#fillin Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7dc112",
   "metadata": {},
   "source": [
    "### Now build a model using `windspeed` instead of `holiday` as a predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = sm.OLS(y_train, X_train[['intercept','temp','windspeed']])\n",
    "results_3 = model_3.fit()\n",
    "summarize(results_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c699c",
   "metadata": {},
   "source": [
    "### Compute the R^2 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1582c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c51d9e",
   "metadata": {},
   "source": [
    "### Compute the MSE for this model on train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_3 = predict(X_train[['intercept','temp','windspeed']], results_3)\n",
    "predictions_test_3 = predict(X_test[['intercept','temp','windspeed']], results_3)\n",
    "\n",
    "print('MSE train: ', mse(y_train, predictions_train_3))\n",
    "print('MSE test: ', mse(y_test, predictions_test_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bcdb24",
   "metadata": {},
   "source": [
    "### Out of the three models, which would you choose? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1ee0f",
   "metadata": {},
   "source": [
    "#fillin Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad51d7f",
   "metadata": {},
   "source": [
    "I would choose Model 3. Among the three models, Model 3 has the lowest test MSE, meaning it performs best at predicting bike rentals on new, unseen data. While Model 2 also improves upon Model 1, Model 3's continuous predictor windspeed captures more variation in hourly bike usage than the binary holiday variable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
